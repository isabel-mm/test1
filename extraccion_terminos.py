import streamlit as st
import pandas as pd
import spacy
import re
from term_extraction import extract_terms_tfidf, extract_terms_pos, extract_terms_cvalue
from io import StringIO

# Cargar modelo de spaCy con cachÃ© para evitar recargas innecesarias
@st.cache_resource
def load_spacy_model():
    return spacy.load("en_core_web_sm")

nlp = load_spacy_model()

# ğŸ“Œ FunciÃ³n de preprocesamiento
def preprocess_text(text, apply_lowercase, remove_stopwords, lemmatize_text, stoplist):
    """Preprocesa el texto segÃºn las opciones seleccionadas por el usuario."""
    doc = nlp(text)
    
    processed_tokens = []
    for token in doc:
        if remove_stopwords and token.is_stop:
            continue
        if lemmatize_text:
            token_text = token.lemma_
        else:
            token_text = token.text.lower() if apply_lowercase else token.text
        
        if stoplist and token_text in stoplist:
            continue
        
        processed_tokens.append(token_text)
    
    return " ".join(processed_tokens)


# ğŸ“Œ FunciÃ³n principal para la extracciÃ³n terminolÃ³gica en Streamlit
def extraccion_terminologica():
    st.title("ğŸ“Œ ExtracciÃ³n automÃ¡tica de tÃ©rminos")

    st.markdown(
        """ 
        ğŸ” **Esta aplicaciÃ³n permite extraer tÃ©rminos desde mÃºltiples archivos de texto.**
        
        - ğŸ“Š **MÃ©todo estadÃ­stico (TF-IDF)**: identifica tÃ©rminos con alta relevancia basÃ¡ndose en su frecuencia e importancia.
        - ğŸ“– **MÃ©todo lingÃ¼Ã­stico (POS Tagging)**: extrae tÃ©rminos clave utilizando categorÃ­as gramaticales.
        - ğŸ”¬ **MÃ©todo hÃ­brido (C-Value)**: identifica tÃ©rminos multi-palabra basÃ¡ndose en su estructura y frecuencia.
        
        ğŸ“‚ **Sube archivos .txt, selecciona el mÃ©todo de extracciÃ³n y descarga los tÃ©rminos en formato CSV.**
        """
    )

    uploaded_files = st.file_uploader("ğŸ“ Carga archivos .txt", type=["txt"], accept_multiple_files=True, key="file_uploader")

    if uploaded_files:
        corpus = ""
        for uploaded_file in uploaded_files:
            stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
            text = stringio.read()
            corpus += text + "\n"

        st.success("ğŸ“‚ Corpus cargado correctamente.")

        # ğŸ“Œ Opciones de preprocesamiento
        with st.expander("âš™ï¸ Opciones de preprocesamiento del corpus"):
            apply_lowercase = st.checkbox("Convertir todo a minÃºsculas")
            remove_stopwords = st.checkbox("Eliminar stopwords en inglÃ©s")
            lemmatize_text = st.checkbox("Aplicar lematizaciÃ³n")
            apply_custom_stoplist = st.checkbox("Aplicar stoplist personalizada")

            stoplist = set()
            if apply_custom_stoplist:
                stoplist_input = st.text_area("Introduce palabras a excluir (separadas por comas)", "")
                stoplist = set(stoplist_input.split(","))

        # Aplicar preprocesamiento
        with st.spinner("ğŸ›  Aplicando preprocesamiento..."):
            corpus = preprocess_text(corpus, apply_lowercase, remove_stopwords, lemmatize_text, stoplist)

        # SelecciÃ³n de mÃ©todo de extracciÃ³n
        method = st.selectbox("ğŸ› ï¸ Selecciona el mÃ©todo de extracciÃ³n", ["MÃ©todo estadÃ­stico (TF-IDF)", "MÃ©todo lingÃ¼Ã­stico (POS)", "MÃ©todo hÃ­brido (C-Value)"])

        # BotÃ³n para iniciar la extracciÃ³n
        if st.button("ğŸš€ Comenzar extracciÃ³n"):
            with st.spinner("ğŸ” Extrayendo tÃ©rminos..."):
                if method == "MÃ©todo estadÃ­stico (TF-IDF)":
                    terms = extract_terms_tfidf(corpus)
                elif method == "MÃ©todo lingÃ¼Ã­stico (POS)":
                    terms = extract_terms_pos(corpus)
                else:
                    terms = extract_terms_cvalue(corpus)

            df_terms = pd.DataFrame(terms, columns=["TÃ©rmino", "Frecuencia"])
            st.dataframe(df_terms)

            # Descargar resultados en CSV
            csv = df_terms.to_csv(index=False).encode("utf-8")
            st.download_button("ğŸ“¥ Descargar tÃ©rminos en CSV", data=csv, file_name="terminos.csv", mime="text/csv")
