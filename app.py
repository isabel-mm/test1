import streamlit as st
import spacy
import subprocess
import sys
import pandas as pd
from io import StringIO
from term_extraction import extract_terms_tfidf, extract_terms_pos, extract_terms_cvalue
from preprocessing import preprocess_text

# Verificar si el modelo de spaCy est√° instalado y descargarlo si no lo est√°
@st.cache_resource
def load_model():
    model_name = "en_core_web_sm"
    try:
        return spacy.load(model_name)
    except OSError:
        st.warning(f"üì• Descargando el modelo de spaCy '{model_name}', espera unos segundos...")
        subprocess.run([sys.executable, "-m", "spacy", "download", model_name], check=True)
        return spacy.load(model_name)

nlp = load_model()

# Men√∫ lateral para seleccionar la funcionalidad
st.sidebar.title("Men√∫ de opciones")
opcion = st.sidebar.radio("Selecciona una funcionalidad", ["Extracci√≥n terminol√≥gica", "Validaci√≥n de t√©rminos"])

# ------------------------------
# Funcionalidad 1: Extracci√≥n terminol√≥gica
# ------------------------------
if opcion == "Extracci√≥n terminol√≥gica":
    st.title("üìå Extracci√≥n autom√°tica de t√©rminos")

    st.markdown(
        """ 
        üîç **Esta aplicaci√≥n permite extraer t√©rminos desde m√∫ltiples archivos de texto.**
        
        - üìä **M√©todo estad√≠stico (TF-IDF):** identifica t√©rminos con alta relevancia bas√°ndose en su frecuencia e importancia.
        - üìñ **M√©todo ling√º√≠stico (POS Tagging):** extrae t√©rminos clave utilizando categor√≠as gramaticales (sustantivos, adjetivos, y estructuras espec√≠ficas).
        - üî¨ **M√©todo h√≠brido (C-Value):** identifica t√©rminos multi-palabra relevantes bas√°ndose en su frecuencia y estructura dentro del texto.
        
        üìÇ **Sube uno o m√°s archivos en texto plano (.txt), configura el preprocesamiento y selecciona un m√©todo para la extracci√≥n. Luego puedes descargar el listado de candidatos a t√©rmino en formato .csv.**
        """
    )

    # Cargar archivos
    uploaded_files = st.file_uploader("üìé Carga uno o m√°s archivos .txt", type=["txt"], accept_multiple_files=True, key="file_uploader")

    if uploaded_files:
        corpus = ""
        for uploaded_file in uploaded_files:
            stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
            text = stringio.read()
            corpus += text + "\n"

        st.success("üìÇ Corpus cargado correctamente.")

        # Opciones de preprocesamiento dentro de un expander
        with st.expander("‚öôÔ∏è Opciones de preprocesamiento del corpus"):
            apply_lowercase = st.checkbox("Convertir todo a min√∫sculas")
            remove_stopwords = st.checkbox("Eliminar stopwords en ingl√©s (excepto 'of')")
            lemmatize_text = st.checkbox("Aplicar lematizaci√≥n")
            apply_custom_stoplist = st.checkbox("Aplicar stoplist acad√©mica")

        # Selecci√≥n de m√©todo de extracci√≥n
        method = st.selectbox("üõ†Ô∏è Selecciona el m√©todo de extracci√≥n", ["M√©todo estad√≠stico (TF-IDF)", "M√©todo ling√º√≠stico (POS)", "M√©todo h√≠brido (C-Value)"])

        # Bot√≥n para iniciar la extracci√≥n
        if st.button("üöÄ Comenzar extracci√≥n"):
            # Aplicar preprocesamiento
            with st.spinner("üõ† Aplicando preprocesamiento..."):
                corpus = preprocess_text(corpus, apply_lowercase, remove_stopwords, lemmatize_text, apply_custom_stoplist)

            st.text_area("üìù Contenido combinado del corpus (preprocesado):", corpus[:1000] + "...", height=200)

            # Aplicar m√©todo seleccionado con indicador de carga
            with st.spinner("üîç Extrayendo t√©rminos..."):
                if method == "M√©todo estad√≠stico (TF-IDF)":
                    terms = extract_terms_tfidf(corpus)
                    st.subheader("üìä T√©rminos extra√≠dos con TF-IDF")
                    df_terms = pd.DataFrame(terms[:50], columns=["T√©rmino", "Puntaje TF-IDF"])
                elif method == "M√©todo ling√º√≠stico (POS)":
                    terms = extract_terms_pos(corpus)
                    st.subheader("üìñ T√©rminos extra√≠dos con POS Tagging (ordenados por frecuencia)")
                    df_terms = pd.DataFrame(terms[:50], columns=["T√©rminos extra√≠dos", "Frecuencia"])
                else:
                    terms = extract_terms_cvalue(corpus)
                    st.subheader("üî¨ T√©rminos extra√≠dos con C-Value")
                    df_terms = pd.DataFrame(terms[:50], columns=["T√©rminos extra√≠dos", "Puntaje C-Value"])

            st.dataframe(df_terms)  # Mostrar los 50 primeros t√©rminos en la interfaz

            # Bot√≥n para descargar t√©rminos
            csv = pd.DataFrame(terms, columns=["T√©rminos extra√≠dos", "Frecuencia"]).to_csv(index=False).encode("utf-8")
            st.download_button(
                label="‚¨áÔ∏è Descargar todos los t√©rminos como CSV",
                data=csv,
                file_name="terminos_extraidos.csv",
                mime="text/csv"
            )

# ------------------------------
# Funcionalidad 2: Validaci√≥n de t√©rminos
# ------------------------------
elif opcion == "Validaci√≥n de t√©rminos":
    st.title("‚úÖ Validaci√≥n de t√©rminos extra√≠dos")
    
    st.markdown(
        """
        üîç **Instrucciones para la validaci√≥n de t√©rminos**
        
        1. **Sube un archivo CSV** con los t√©rminos extra√≠dos.
        2. **El archivo debe contener al menos una columna llamada "T√©rminos extra√≠dos" (si has utilizado el extractor en esta misma app, ya estar√° as√≠ por defecto)**.
        3. **Opcionalmente**, puede contener una columna "Es t√©rmino" (con valores `True` o `False`).  
        4. Si la columna "Es t√©rmino" no est√° presente, se a√±adir√° autom√°ticamente para que puedas marcar los t√©rminos manualmente, ¬°no te preocupes!  
        5. Puedes modificar las marcas en la tabla y luego descargar el archivo validado.
        
        üìå **Aqu√≠ tienes un ejemplo de estructura esperada del archivo CSV üòä**
        
        | T√©rminos extra√≠dos | Es t√©rmino |
        |--------------------|------------|
        | aprendizaje autom√°tico | True |
        | modelo ling√º√≠stico | False |
        | procesamiento del lenguaje natural | True |

        üìé **Sube tu archivo CSV aqu√≠:**
        """
    )

    # Cargar el CSV
    uploaded_file = st.file_uploader()

    if uploaded_file:
        df = pd.read_csv(uploaded_file)

        # Verificar si la columna de t√©rminos existe
        if "T√©rminos extra√≠dos" not in df.columns:
            st.error("‚ö†Ô∏è El archivo debe contener una columna llamada 'T√©rminos extra√≠dos'.")
        else:
            # A√±adir una columna de validaci√≥n si no existe
            if "Es t√©rmino" not in df.columns:
                df["Es t√©rmino"] = False  # Inicialmente, todos los t√©rminos est√°n en False

            # Mostrar los t√©rminos en una tabla editable
            st.subheader("üîç Revisi√≥n de t√©rminos")
            df_editable = st.data_editor(df, num_rows="dynamic", key="term_editor")

            # Bot√≥n para descargar el CSV validado
            if st.button("‚¨áÔ∏è Descargar CSV validado"):
                df_editable.to_csv("terminos_validados.csv", index=False)
                st.success("‚úÖ Archivo guardado como terminos_validados.csv")
                st.download_button(
                    label="üì• Descargar CSV validado",
                    data=df_editable.to_csv(index=False),
                    file_name="terminos_validados.csv",
                    mime="text/csv"
                )
