import streamlit as st
import spacy
import subprocess
import sys
import pandas as pd
from io import StringIO
from term_extraction import extract_terms_tfidf, extract_terms_pos, extract_terms_cvalue
from preprocessing import preprocess_text

# Verificar si el modelo de spaCy estÃ¡ instalado y descargarlo si no lo estÃ¡
@st.cache_resource
def load_model():
    model_name = "en_core_web_sm"
    try:
        return spacy.load(model_name)
    except OSError:
        st.warning(f"ğŸ“¥ Descargando el modelo de spaCy '{model_name}', espera unos segundos...")
        subprocess.run([sys.executable, "-m", "spacy", "download", model_name], check=True)
        return spacy.load(model_name)

nlp = load_model()

# MenÃº lateral para seleccionar la funcionalidad
st.sidebar.title("MenÃº de opciones")
opcion = st.sidebar.radio("Selecciona una funcionalidad", ["ExtracciÃ³n terminolÃ³gica", "ValidaciÃ³n de tÃ©rminos"])

# ------------------------------
# Funcionalidad 1: ExtracciÃ³n terminolÃ³gica
# ------------------------------
if opcion == "ExtracciÃ³n terminolÃ³gica":
    st.title("ğŸ“Œ ExtracciÃ³n automÃ¡tica de tÃ©rminos")

    st.markdown(
        """ 
        ğŸ” **Esta aplicaciÃ³n permite extraer tÃ©rminos desde mÃºltiples archivos de texto.**
        
        - ğŸ“Š **MÃ©todo estadÃ­stico (TF-IDF):** identifica tÃ©rminos con alta relevancia basÃ¡ndose en su frecuencia e importancia.
        - ğŸ“– **MÃ©todo lingÃ¼Ã­stico (POS Tagging):** extrae tÃ©rminos clave utilizando categorÃ­as gramaticales (sustantivos, adjetivos, y estructuras especÃ­ficas).
        - ğŸ”¬ **MÃ©todo hÃ­brido (C-Value):** identifica tÃ©rminos multi-palabra relevantes basÃ¡ndose en su frecuencia y estructura dentro del texto.
        
        ğŸ“‚ **Sube uno o mÃ¡s archivos en texto plano (.txt), configura el preprocesamiento y selecciona un mÃ©todo para la extracciÃ³n. Luego puedes descargar el listado de candidatos a tÃ©rmino en formato .csv.**
        """
    )

    # Cargar archivos
    uploaded_files = st.file_uploader("ğŸ“ Carga uno o mÃ¡s archivos .txt", type=["txt"], accept_multiple_files=True, key="file_uploader")

    if uploaded_files:
        corpus = ""
        for uploaded_file in uploaded_files:
            stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
            text = stringio.read()
            corpus += text + "\n"

        st.success("ğŸ“‚ Corpus cargado correctamente.")

        # Opciones de preprocesamiento dentro de un expander
        with st.expander("âš™ï¸ Opciones de preprocesamiento del corpus"):
            apply_lowercase = st.checkbox("Convertir todo a minÃºsculas")
            remove_stopwords = st.checkbox("Eliminar stopwords en inglÃ©s (excepto 'of')")
            lemmatize_text = st.checkbox("Aplicar lematizaciÃ³n")
            apply_custom_stoplist = st.checkbox("Aplicar stoplist acadÃ©mica")

        # SelecciÃ³n de mÃ©todo de extracciÃ³n
        method = st.selectbox("ğŸ› ï¸ Selecciona el mÃ©todo de extracciÃ³n", ["MÃ©todo estadÃ­stico (TF-IDF)", "MÃ©todo lingÃ¼Ã­stico (POS)", "MÃ©todo hÃ­brido (C-Value)"])

        # BotÃ³n para iniciar la extracciÃ³n
        if st.button("ğŸš€ Comenzar extracciÃ³n"):
            # Aplicar preprocesamiento
            with st.spinner("ğŸ›  Aplicando preprocesamiento..."):
                corpus = preprocess_text(corpus, apply_lowercase, remove_stopwords, lemmatize_text, apply_custom_stoplist)

            st.text_area("ğŸ“ Contenido combinado del corpus (preprocesado):", corpus[:1000] + "...", height=200)

            # Aplicar mÃ©todo seleccionado con indicador de carga
            with st.spinner("ğŸ” Extrayendo tÃ©rminos..."):
                if method == "MÃ©todo estadÃ­stico (TF-IDF)":
                    terms = extract_terms_tfidf(corpus)
                    st.subheader("ğŸ“Š TÃ©rminos extraÃ­dos con TF-IDF")
                    df_terms = pd.DataFrame(terms[:50], columns=["TÃ©rmino", "Puntaje TF-IDF"])
                elif method == "MÃ©todo lingÃ¼Ã­stico (POS)":
                    terms = extract_terms_pos(corpus)
                    st.subheader("ğŸ“– TÃ©rminos extraÃ­dos con POS Tagging (ordenados por frecuencia)")
                    df_terms = pd.DataFrame(terms[:50], columns=["TÃ©rminos extraÃ­dos", "Frecuencia"])
                else:
                    terms = extract_terms_cvalue(corpus)
                    st.subheader("ğŸ”¬ TÃ©rminos extraÃ­dos con C-Value")
                    df_terms = pd.DataFrame(terms[:50], columns=["TÃ©rminos extraÃ­dos", "Puntaje C-Value"])

            st.dataframe(df_terms)  # Mostrar los 50 primeros tÃ©rminos en la interfaz

            # BotÃ³n para descargar tÃ©rminos
            csv = pd.DataFrame(terms, columns=["TÃ©rminos extraÃ­dos", "Frecuencia"]).to_csv(index=False).encode("utf-8")
            st.download_button(
                label="â¬‡ï¸ Descargar todos los tÃ©rminos como CSV",
                data=csv,
                file_name="terminos_extraidos.csv",
                mime="text/csv"
            )

# ------------------------------
# Funcionalidad 2: ValidaciÃ³n de tÃ©rminos
# ------------------------------
elif opcion == "ValidaciÃ³n de tÃ©rminos":
    st.title("âœ… ValidaciÃ³n de tÃ©rminos extraÃ­dos")
    
    st.markdown(
        """
        ğŸ” **Instrucciones para la validaciÃ³n de tÃ©rminos**
        
        1. **Sube un archivo CSV** con los tÃ©rminos extraÃ­dos.
        2. **El archivo debe contener al menos una columna llamada "TÃ©rminos extraÃ­dos" (si has utilizado el extractor en esta misma app, ya estarÃ¡ asÃ­ por defecto)**.
        3. **Opcionalmente**, puede contener una columna "Es tÃ©rmino" (con valores `True` o `False`).  
        4. Si la columna "Es tÃ©rmino" no estÃ¡ presente, se aÃ±adirÃ¡ automÃ¡ticamente para que puedas marcar los tÃ©rminos manualmente, Â¡no te preocupes!  
        5. Puedes modificar las marcas en la tabla y luego descargar el archivo validado.
        
        ğŸ“Œ **AquÃ­ tienes un ejemplo de estructura esperada del archivo CSV ğŸ˜Š**
        
        | TÃ©rminos extraÃ­dos | Es tÃ©rmino |
        |--------------------|------------|
        | aprendizaje automÃ¡tico | True |
        | modelo lingÃ¼Ã­stico | False |
        | procesamiento del lenguaje natural | True |
        
        """
    )

    # Cargar el CSV
    uploaded_file = st.file_uploader("ğŸ“ Sube tu archivo CSV aquÃ­", type=["csv"])

    if uploaded_file:
        df = pd.read_csv(uploaded_file)

        # Verificar si la columna de tÃ©rminos existe
        if "TÃ©rminos extraÃ­dos" not in df.columns:
            st.error("âš ï¸ Recuerda, el archivo debe contener una columna llamada 'TÃ©rminos extraÃ­dos'.")
        else:
            # AÃ±adir una columna de validaciÃ³n si no existe
            if "Es tÃ©rmino" not in df.columns:
                df["Es tÃ©rmino"] = False  # Inicialmente, todos los tÃ©rminos estÃ¡n en False

            # Mostrar los tÃ©rminos en una tabla editable
            st.subheader("ğŸ” RevisiÃ³n de tÃ©rminos")
            df_editable = st.data_editor(df, num_rows="dynamic", key="term_editor")

            # CÃ¡lculo de precisiÃ³n: % de tÃ©rminos validados y descartados
            total_terms = len(df_editable)
            validated_terms = df_editable["Es tÃ©rmino"].sum()
            discarded_terms = total_terms - validated_terms

            validated_percentage = (validated_terms / total_terms) * 100 if total_terms > 0 else 0
            discarded_percentage = (discarded_terms / total_terms) * 100 if total_terms > 0 else 0

            # Mostrar estadÃ­sticas de precisiÃ³n
            st.subheader("ğŸ“Š EstadÃ­sticas de validaciÃ³n")
            st.write(f"âœ… **TÃ©rminos validados:** {validated_terms} ({validated_percentage:.2f}%)")
            st.write(f"âŒ **TÃ©rminos descartados:** {discarded_terms} ({discarded_percentage:.2f}%)")

            # GrÃ¡fico de precisiÃ³n
            st.bar_chart({"Validado (%)": validated_percentage, "Descartado (%)": discarded_percentage})

            # BotÃ³n para descargar el CSV validado
            if st.button("â¬‡ï¸ Descargar CSV validado"):
                df_editable.to_csv("terminos_validados.csv", index=False)
                st.success("âœ… Archivo guardado como terminos_validados.csv")
                st.download_button(
                    label="ğŸ“¥ Descargar CSV validado",
                    data=df_editable.to_csv(index=False),
                    file_name="terminos_validados.csv",
                    mime="text/csv"
                )

