import streamlit as st
import spacy
import subprocess
import sys
import pandas as pd
from io import StringIO
from term_extraction import extract_terms_tfidf, extract_terms_pos, extract_terms_cvalue
from preprocessing import preprocess_text

# Verificar si el modelo de spaCy est√° instalado y descargarlo si no lo est√°
@st.cache_resource
def load_model():
    model_name = "en_core_web_sm"
    try:
        return spacy.load(model_name)
    except OSError:
        st.warning(f"üì• Descargando el modelo de spaCy '{model_name}', espera unos segundos...")
        subprocess.run([sys.executable, "-m", "spacy", "download", model_name], check=True)
        return spacy.load(model_name)

nlp = load_model()

# Interfaz en Streamlit
st.title("üìå Extracci√≥n autom√°tica de t√©rminos")

st.markdown(
    """ 
    üîç **Esta aplicaci√≥n permite extraer t√©rminos desde m√∫ltiples archivos de texto.**
    
    - üìä **M√©todo estad√≠stico (TF-IDF):** identifica t√©rminos con alta relevancia bas√°ndose en su frecuencia e importancia.
    - üìñ **M√©todo ling√º√≠stico (POS Tagging):** extrae t√©rminos clave utilizando categor√≠as gramaticales (sustantivos, adjetivos, y estructuras espec√≠ficas).
    - üî¨ **M√©todo h√≠brido (C-Value):** identifica t√©rminos multi-palabra relevantes bas√°ndose en su frecuencia y estructura dentro del texto.
    
    üìÇ **Sube uno o m√°s archivos en texto plano (.txt) y elige un m√©todo para la extracci√≥n. Luego puedes descargar el listado de candidatos a t√©rmino en formato .csv.**
    """
)

# Cargar archivos
uploaded_files = st.file_uploader("üìé Carga uno o m√°s archivos .txt", type=["txt"], accept_multiple_files=True, key="file_uploader")

if uploaded_files:
    corpus = ""
    file_names = []
    
    for uploaded_file in uploaded_files:
        stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
        text = stringio.read()
        corpus += text + "\n"
        file_names.append(uploaded_file.name)
    
    st.subheader("üìú Archivos cargados")
    st.write(", ".join(file_names))
    
    # Opciones de preprocesamiento dentro de un expander
    with st.expander("‚öôÔ∏è Opciones de preprocesamiento del corpus"):
        apply_lowercase = st.checkbox("Convertir todo a min√∫sculas")
        remove_stopwords = st.checkbox("Eliminar stopwords en ingl√©s (excepto 'of')")
        lemmatize_text = st.checkbox("Aplicar lematizaci√≥n")
        apply_custom_stoplist = st.checkbox("Aplicar stoplist acad√©mica")
    
    # Aplicar preprocesamiento
    corpus = preprocess_text(corpus, apply_lowercase, remove_stopwords, lemmatize_text, apply_custom_stoplist)
    
    st.text_area("üìù Contenido combinado del corpus (preprocesado):", corpus[:1000] + "...", height=200)
    
    # Selecci√≥n de m√©todo de extracci√≥n
    method = st.selectbox("üõ†Ô∏è Selecciona el m√©todo de extracci√≥n", ["M√©todo estad√≠stico (TF-IDF)", "M√©todo ling√º√≠stico (POS)", "M√©todo h√≠brido (C-Value)"])
    
    # Aplicar m√©todo seleccionado con indicador de carga
    if method:
        with st.spinner("üîç Extrayendo t√©rminos..."):
            if method == "M√©todo estad√≠stico (TF-IDF)":
                terms = extract_terms_tfidf(corpus)
                st.subheader("üìä T√©rminos extra√≠dos con TF-IDF")
                df_terms = pd.DataFrame(terms[:50], columns=["T√©rmino", "Puntaje TF-IDF"])
            elif method == "M√©todo ling√º√≠stico (POS)":
                terms = extract_terms_pos(corpus)
                st.subheader("üìñ T√©rminos extra√≠dos con POS Tagging (ordenados por frecuencia)")
                df_terms = pd.DataFrame(terms[:50], columns=["T√©rminos extra√≠dos", "Frecuencia"])
            else:
                terms = extract_terms_cvalue(corpus)
                st.subheader("üî¨ T√©rminos extra√≠dos con C-Value")
                df_terms = pd.DataFrame(terms[:50], columns=["T√©rminos extra√≠dos", "Puntaje C-Value"])
    
        st.dataframe(df_terms)  # Mostrar los 50 primeros t√©rminos en la interfaz
    
        # Bot√≥n para descargar t√©rminos
        csv = pd.DataFrame(terms, columns=["T√©rminos extra√≠dos", "Frecuencia"]).to_csv(index=False).encode("utf-8")
        st.download_button(
            label="‚¨áÔ∏è Descargar todos los t√©rminos como CSV",
            data=csv,
            file_name="terminos_extraidos.csv",
            mime="text/csv"
        )
