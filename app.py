import streamlit as st
import spacy
import subprocess
import sys
import pandas as pd
from io import StringIO
from term_extraction import extract_terms_tfidf, extract_terms_pos, extract_terms_cvalue
from preprocessing import preprocess_text

# Verificar si el modelo de spaCy estÃ¡ instalado y descargarlo si no lo estÃ¡
@st.cache_resource
def load_model():
    model_name = "en_core_web_sm"
    try:
        return spacy.load(model_name)
    except OSError:
        st.warning(f"ğŸ“¥ Descargando el modelo de spaCy '{model_name}', espera unos segundos...")
        subprocess.run([sys.executable, "-m", "spacy", "download", model_name], check=True)
        return spacy.load(model_name)

nlp = load_model()

# Interfaz en Streamlit
st.title("ğŸ“Œ ExtracciÃ³n automÃ¡tica de tÃ©rminos")

st.markdown(
    """ 
    ğŸ” **Esta aplicaciÃ³n permite extraer tÃ©rminos desde mÃºltiples archivos de texto.**
    
    - ğŸ“Š **MÃ©todo estadÃ­stico (TF-IDF):** identifica tÃ©rminos con alta relevancia basÃ¡ndose en su frecuencia e importancia.
    - ğŸ“– **MÃ©todo lingÃ¼Ã­stico (POS Tagging):** extrae tÃ©rminos clave utilizando categorÃ­as gramaticales (sustantivos, adjetivos, y estructuras especÃ­ficas).
    - ğŸ”¬ **MÃ©todo hÃ­brido (C-Value):** identifica tÃ©rminos multi-palabra relevantes basÃ¡ndose en su frecuencia y estructura dentro del texto.
    
    ğŸ“‚ **Sube uno o mÃ¡s archivos en texto plano (.txt), configura el preprocesamiento y selecciona un mÃ©todo para la extracciÃ³n. Luego puedes descargar el listado de candidatos a tÃ©rmino en formato .csv.**
    """
)

# Cargar archivos
uploaded_files = st.file_uploader("ğŸ“ Carga uno o mÃ¡s archivos .txt", type=["txt"], accept_multiple_files=True, key="file_uploader")

if uploaded_files:
    corpus = ""
    for uploaded_file in uploaded_files:
        stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
        text = stringio.read()
        corpus += text + "\n"
    
    st.success("ğŸ“‚ Corpus cargado correctamente.")
    
    # Opciones de preprocesamiento dentro de un expander
    with st.expander("âš™ï¸ Opciones de preprocesamiento del corpus"):
        apply_lowercase = st.checkbox("Convertir todo a minÃºsculas")
        remove_stopwords = st.checkbox("Eliminar stopwords en inglÃ©s (excepto 'of')")
        lemmatize_text = st.checkbox("Aplicar lematizaciÃ³n")
        apply_custom_stoplist = st.checkbox("Aplicar stoplist acadÃ©mica")
    
    # SelecciÃ³n de mÃ©todo de extracciÃ³n
    method = st.selectbox("ğŸ› ï¸ Selecciona el mÃ©todo de extracciÃ³n", ["MÃ©todo estadÃ­stico (TF-IDF)", "MÃ©todo lingÃ¼Ã­stico (POS)", "MÃ©todo hÃ­brido (C-Value)"])
    
    # BotÃ³n para iniciar la extracciÃ³n
    if st.button("ğŸš€ Comenzar extracciÃ³n"):
        # Aplicar preprocesamiento
        with st.spinner("ğŸ›  Aplicando preprocesamiento..."):
            corpus = preprocess_text(corpus, apply_lowercase, remove_stopwords, lemmatize_text, apply_custom_stoplist)
        
        st.text_area("ğŸ“ Contenido combinado del corpus (preprocesado):", corpus[:1000] + "...", height=200)
        
        # Aplicar mÃ©todo seleccionado con indicador de carga
        with st.spinner("ğŸ” Extrayendo tÃ©rminos..."):
            if method == "MÃ©todo estadÃ­stico (TF-IDF)":
                terms = extract_terms_tfidf(corpus)
                st.subheader("ğŸ“Š TÃ©rminos extraÃ­dos con TF-IDF")
                df_terms = pd.DataFrame(terms[:50], columns=["TÃ©rmino", "Puntaje TF-IDF"])
            elif method == "MÃ©todo lingÃ¼Ã­stico (POS)":
                terms = extract_terms_pos(corpus)
                st.subheader("ğŸ“– TÃ©rminos extraÃ­dos con POS Tagging (ordenados por frecuencia)")
                df_terms = pd.DataFrame(terms[:50], columns=["TÃ©rminos extraÃ­dos", "Frecuencia"])
            else:
                terms = extract_terms_cvalue(corpus)
                st.subheader("ğŸ”¬ TÃ©rminos extraÃ­dos con C-Value")
                df_terms = pd.DataFrame(terms[:50], columns=["TÃ©rminos extraÃ­dos", "Puntaje C-Value"])
        
        st.dataframe(df_terms)  # Mostrar los 50 primeros tÃ©rminos en la interfaz
        
        # BotÃ³n para descargar tÃ©rminos
        csv = pd.DataFrame(terms, columns=["TÃ©rminos extraÃ­dos", "Frecuencia"]).to_csv(index=False).encode("utf-8")
        st.download_button(
            label="â¬‡ï¸ Descargar todos los tÃ©rminos como CSV",
            data=csv,
            file_name="terminos_extraidos.csv",
            mime="text/csv"
        )
