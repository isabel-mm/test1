import streamlit as st
import spacy
import subprocess
import sys
import pandas as pd
import matplotlib.pyplot as plt
from io import StringIO
from term_extraction import extract_terms_tfidf, extract_terms_pos, extract_terms_cvalue
from preprocessing import preprocess_text

# Verificar si el modelo de spaCy estÃ¡ instalado y descargarlo si no lo estÃ¡
@st.cache_resource
def load_model():
    model_name = "en_core_web_sm"
    try:
        return spacy.load(model_name)
    except OSError:
        st.warning(f"ğŸ“¥ Descargando el modelo de spaCy '{model_name}', espera unos segundos...")
        subprocess.run([sys.executable, "-m", "spacy", "download", model_name], check=True)
        return spacy.load(model_name)

nlp = load_model()

# MenÃº lateral para seleccionar la funcionalidad
st.sidebar.title("MenÃº de opciones")
opcion = st.sidebar.radio("Selecciona una funcionalidad", ["ExtracciÃ³n terminolÃ³gica", "ValidaciÃ³n de tÃ©rminos"])

# ------------------------------
# Funcionalidad 1: ExtracciÃ³n terminolÃ³gica
# ------------------------------
if opcion == "ExtracciÃ³n terminolÃ³gica":
    st.title("ğŸ“Œ ExtracciÃ³n automÃ¡tica de tÃ©rminos")

    st.markdown(
        """ 
        ğŸ” **Esta aplicaciÃ³n permite extraer tÃ©rminos desde mÃºltiples archivos de texto.**
        
        ğŸ“‚ **Sube archivos .txt, selecciona el mÃ©todo de extracciÃ³n y descarga los tÃ©rminos extraÃ­dos.**
        """
    )

    # Cargar archivos
    uploaded_files = st.file_uploader("ğŸ“ Carga uno o mÃ¡s archivos .txt", type=["txt"], accept_multiple_files=True, key="file_uploader")

    if uploaded_files:
        corpus = ""
        for uploaded_file in uploaded_files:
            stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
            text = stringio.read()
            corpus += text + "\n"

        st.success("ğŸ“‚ Corpus cargado correctamente.")

        # Opciones de preprocesamiento
        with st.expander("âš™ï¸ Opciones de preprocesamiento del corpus"):
            apply_lowercase = st.checkbox("Convertir todo a minÃºsculas")
            remove_stopwords = st.checkbox("Eliminar stopwords en inglÃ©s (excepto 'of')")
            lemmatize_text = st.checkbox("Aplicar lematizaciÃ³n")
            apply_custom_stoplist = st.checkbox("Aplicar stoplist acadÃ©mica")

        # SelecciÃ³n de mÃ©todo de extracciÃ³n
        method = st.selectbox("ğŸ› ï¸ Selecciona el mÃ©todo de extracciÃ³n", ["MÃ©todo estadÃ­stico (TF-IDF)", "MÃ©todo lingÃ¼Ã­stico (POS)", "MÃ©todo hÃ­brido (C-Value)"])

        # BotÃ³n para iniciar la extracciÃ³n
        if st.button("ğŸš€ Comenzar extracciÃ³n"):
            # Aplicar preprocesamiento
            with st.spinner("ğŸ›  Aplicando preprocesamiento..."):
                corpus = preprocess_text(corpus, apply_lowercase, remove_stopwords, lemmatize_text, apply_custom_stoplist)

            st.text_area("ğŸ“ Contenido combinado del corpus (preprocesado):", corpus[:1000] + "...", height=200)

            # Aplicar mÃ©todo seleccionado
            with st.spinner("ğŸ” Extrayendo tÃ©rminos..."):
                if method == "MÃ©todo estadÃ­stico (TF-IDF)":
                    terms = extract_terms_tfidf(corpus)
                    st.subheader("ğŸ“Š TÃ©rminos extraÃ­dos con TF-IDF")
                    df_terms = pd.DataFrame(terms[:50], columns=["TÃ©rmino", "Puntaje TF-IDF"])
                elif method == "MÃ©todo lingÃ¼Ã­stico (POS)":
                    terms = extract_terms_pos(corpus)
                    st.subheader("ğŸ“– TÃ©rminos extraÃ­dos con POS Tagging")
                    df_terms = pd.DataFrame(terms[:50], columns=["TÃ©rminos extraÃ­dos", "Frecuencia"])
                else:
                    terms = extract_terms_cvalue(corpus)
                    st.subheader("ğŸ”¬ TÃ©rminos extraÃ­dos con C-Value")
                    df_terms = pd.DataFrame(terms[:50], columns=["TÃ©rminos extraÃ­dos", "Puntaje C-Value"])

            st.dataframe(df_terms)

            # Descargar tÃ©rminos en CSV
            csv = pd.DataFrame(terms, columns=["TÃ©rminos extraÃ­dos", "Frecuencia"]).to_csv(index=False).encode("utf-8")
            st.download_button("â¬‡ï¸ Descargar tÃ©rminos (CSV)", data=csv, file_name="terminos_extraidos.csv", mime="text/csv")

# ------------------------------
# Funcionalidad 2: ValidaciÃ³n de tÃ©rminos
# ------------------------------
elif opcion == "ValidaciÃ³n de tÃ©rminos":
    st.title("âœ… ValidaciÃ³n de tÃ©rminos extraÃ­dos")

    st.markdown(
        """
        ğŸ” **Instrucciones para la validaciÃ³n de tÃ©rminos**
        
        ğŸ“ **Sube un archivo CSV con los tÃ©rminos extraÃ­dos**.
        """
    )

    uploaded_file = st.file_uploader("ğŸ“ Carga el archivo CSV", type=["csv"])

    if uploaded_file:
        df = pd.read_csv(uploaded_file)

        # Verificar si la columna de tÃ©rminos existe
        if "TÃ©rminos extraÃ­dos" not in df.columns:
            st.error("âš ï¸ El archivo debe contener una columna llamada 'TÃ©rminos extraÃ­dos'.")
        else:
            # AÃ±adir una columna de validaciÃ³n si no existe
            if "Es tÃ©rmino" not in df.columns:
                df["Es tÃ©rmino"] = False

            # Filtros avanzados
            st.subheader("ğŸ¯ Filtros de visualizaciÃ³n")
            search_term = st.text_input("ğŸ” Buscar un tÃ©rmino especÃ­fico:")
            show_unvalidated = st.checkbox("Mostrar solo tÃ©rminos no validados")

            if search_term:
                df = df[df["TÃ©rminos extraÃ­dos"].str.contains(search_term, case=False, na=False)]

            if show_unvalidated:
                df = df[df["Es tÃ©rmino"] == False]

            # Tabla interactiva
            st.subheader("ğŸ” RevisiÃ³n de tÃ©rminos")
            df_editable = st.data_editor(df, num_rows="dynamic", key="term_editor")

            # EstadÃ­sticas bÃ¡sicas
            st.subheader("ğŸ“Š EstadÃ­sticas de tÃ©rminos validados")
            df_validated = df_editable[df_editable["Es tÃ©rmino"] == True]
            st.write(f"ğŸ“Œ **NÃºmero total de tÃ©rminos validados:** {len(df_validated)}")

            # GrÃ¡fico de barras de tÃ©rminos mÃ¡s frecuentes
            fig, ax = plt.subplots()
            df_validated["TÃ©rminos extraÃ­dos"].value_counts().head(10).plot(kind="bar", ax=ax)
            ax.set_title("ğŸ” TÃ©rminos mÃ¡s frecuentes")
            ax.set_xlabel("TÃ©rmino")
            ax.set_ylabel("Frecuencia")
            st.pyplot(fig)

            # Opciones de descarga
            st.subheader("ğŸ“¥ Descargar tÃ©rminos validados")

            # CSV
            csv_validated = df_validated.to_csv(index=False).encode("utf-8")
            st.download_button("ğŸ“¥ Descargar CSV", data=csv_validated, file_name="terminos_validados.csv", mime="text/csv")

            # JSON
            json_data = df_validated.to_json(orient="records", indent=4)
            st.download_button("ğŸ“¥ Descargar JSON", data=json_data, file_name="terminos_validados.json", mime="application/json")

            # TXT
            txt_data = "\n".join(df_validated["TÃ©rminos extraÃ­dos"])
            st.download_button("ğŸ“¥ Descargar TXT", data=txt_data, file_name="terminos_validados.txt", mime="text/plain")
